{"ast":null,"code":"import { addEventListener, addTelemetryDebug, assign, concatBuffers } from '@datadog/browser-core';\nexport function createDeflateEncoder(configuration, worker, streamId) {\n  var rawBytesCount = 0;\n  var compressedData = [];\n  var compressedDataTrailer;\n  var nextWriteActionId = 0;\n  var pendingWriteActions = [];\n  var removeMessageListener = addEventListener(configuration, worker, 'message', function (_a) {\n    var workerResponse = _a.data;\n    if (workerResponse.type !== 'wrote' || workerResponse.streamId !== streamId) {\n      return;\n    }\n    rawBytesCount += workerResponse.additionalBytesCount;\n    compressedData.push(workerResponse.result);\n    compressedDataTrailer = workerResponse.trailer;\n    var nextPendingAction = pendingWriteActions.shift();\n    if (nextPendingAction && nextPendingAction.id === workerResponse.id) {\n      if (nextPendingAction.writeCallback) {\n        nextPendingAction.writeCallback(workerResponse.result.byteLength);\n      } else if (nextPendingAction.finishCallback) {\n        nextPendingAction.finishCallback();\n      }\n    } else {\n      removeMessageListener();\n      addTelemetryDebug('Worker responses received out of order.');\n    }\n  }).stop;\n  function consumeResult() {\n    var output = compressedData.length === 0 ? new Uint8Array(0) : concatBuffers(compressedData.concat(compressedDataTrailer));\n    var result = {\n      rawBytesCount: rawBytesCount,\n      output: output,\n      outputBytesCount: output.byteLength,\n      encoding: 'deflate'\n    };\n    rawBytesCount = 0;\n    compressedData = [];\n    return result;\n  }\n  function sendResetIfNeeded() {\n    if (nextWriteActionId > 0) {\n      worker.postMessage({\n        action: 'reset',\n        streamId: streamId\n      });\n      nextWriteActionId = 0;\n    }\n  }\n  return {\n    isAsync: true,\n    get isEmpty() {\n      return nextWriteActionId === 0;\n    },\n    write: function (data, callback) {\n      worker.postMessage({\n        action: 'write',\n        id: nextWriteActionId,\n        data: data,\n        streamId: streamId\n      });\n      pendingWriteActions.push({\n        id: nextWriteActionId,\n        writeCallback: callback,\n        data: data\n      });\n      nextWriteActionId += 1;\n    },\n    finish: function (callback) {\n      sendResetIfNeeded();\n      if (!pendingWriteActions.length) {\n        callback(consumeResult());\n      } else {\n        // Make sure we do not call any write callback\n        pendingWriteActions.forEach(function (pendingWriteAction) {\n          delete pendingWriteAction.writeCallback;\n        });\n        // Wait for the last action to finish before calling the finish callback\n        pendingWriteActions[pendingWriteActions.length - 1].finishCallback = function () {\n          return callback(consumeResult());\n        };\n      }\n    },\n    finishSync: function () {\n      sendResetIfNeeded();\n      var pendingData = pendingWriteActions.map(function (pendingWriteAction) {\n        // Make sure we do not call any write or finish callback\n        delete pendingWriteAction.writeCallback;\n        delete pendingWriteAction.finishCallback;\n        return pendingWriteAction.data;\n      }).join('');\n      return assign(consumeResult(), {\n        pendingData: pendingData\n      });\n    },\n    estimateEncodedBytesCount: function (data) {\n      // This is a rough estimation of the data size once it'll be encoded by deflate. We observed\n      // that if it's the first chunk of data pushed to the stream, the ratio is lower (3-4), but\n      // after that the ratio is greater (10+). We chose 8 here, which (on average) seems to produce\n      // requests of the expected size.\n      return data.length / 8;\n    },\n    stop: function () {\n      removeMessageListener();\n    }\n  };\n}","map":{"version":3,"names":["addEventListener","addTelemetryDebug","assign","concatBuffers","createDeflateEncoder","configuration","worker","streamId","rawBytesCount","compressedData","compressedDataTrailer","nextWriteActionId","pendingWriteActions","removeMessageListener","_a","workerResponse","data","type","additionalBytesCount","push","result","trailer","nextPendingAction","shift","id","writeCallback","byteLength","finishCallback","stop","consumeResult","output","length","Uint8Array","concat","outputBytesCount","encoding","sendResetIfNeeded","postMessage","action","isAsync","isEmpty","write","callback","finish","forEach","pendingWriteAction","finishSync","pendingData","map","join","estimateEncodedBytesCount"],"sources":["D:\\edu'\\Spritle\\Spritle\\node_modules\\@datadog\\browser-rum\\src\\domain\\deflate\\deflateEncoder.ts"],"sourcesContent":["import type {\n  DeflateWorkerResponse,\n  DeflateEncoder,\n  DeflateEncoderStreamId,\n  DeflateWorker,\n  EncoderResult,\n} from '@datadog/browser-core'\nimport type { RumConfiguration } from '@datadog/browser-rum-core'\nimport { addEventListener, addTelemetryDebug, assign, concatBuffers } from '@datadog/browser-core'\n\nexport function createDeflateEncoder(\n  configuration: RumConfiguration,\n  worker: DeflateWorker,\n  streamId: DeflateEncoderStreamId\n): DeflateEncoder {\n  let rawBytesCount = 0\n  let compressedData: Uint8Array[] = []\n  let compressedDataTrailer: Uint8Array\n\n  let nextWriteActionId = 0\n  const pendingWriteActions: Array<{\n    writeCallback?: (additionalEncodedBytesCount: number) => void\n    finishCallback?: () => void\n    id: number\n    data: string\n  }> = []\n\n  const { stop: removeMessageListener } = addEventListener(\n    configuration,\n    worker,\n    'message',\n    ({ data: workerResponse }: MessageEvent<DeflateWorkerResponse>) => {\n      if (workerResponse.type !== 'wrote' || (workerResponse.streamId as DeflateEncoderStreamId) !== streamId) {\n        return\n      }\n\n      rawBytesCount += workerResponse.additionalBytesCount\n      compressedData.push(workerResponse.result)\n      compressedDataTrailer = workerResponse.trailer\n\n      const nextPendingAction = pendingWriteActions.shift()\n      if (nextPendingAction && nextPendingAction.id === workerResponse.id) {\n        if (nextPendingAction.writeCallback) {\n          nextPendingAction.writeCallback(workerResponse.result.byteLength)\n        } else if (nextPendingAction.finishCallback) {\n          nextPendingAction.finishCallback()\n        }\n      } else {\n        removeMessageListener()\n        addTelemetryDebug('Worker responses received out of order.')\n      }\n    }\n  )\n\n  function consumeResult(): EncoderResult<Uint8Array> {\n    const output =\n      compressedData.length === 0 ? new Uint8Array(0) : concatBuffers(compressedData.concat(compressedDataTrailer))\n    const result: EncoderResult<Uint8Array> = {\n      rawBytesCount,\n      output,\n      outputBytesCount: output.byteLength,\n      encoding: 'deflate',\n    }\n    rawBytesCount = 0\n    compressedData = []\n    return result\n  }\n\n  function sendResetIfNeeded() {\n    if (nextWriteActionId > 0) {\n      worker.postMessage({\n        action: 'reset',\n        streamId,\n      })\n      nextWriteActionId = 0\n    }\n  }\n\n  return {\n    isAsync: true,\n\n    get isEmpty() {\n      return nextWriteActionId === 0\n    },\n\n    write(data, callback) {\n      worker.postMessage({\n        action: 'write',\n        id: nextWriteActionId,\n        data,\n        streamId,\n      })\n      pendingWriteActions.push({\n        id: nextWriteActionId,\n        writeCallback: callback,\n        data,\n      })\n      nextWriteActionId += 1\n    },\n\n    finish(callback) {\n      sendResetIfNeeded()\n\n      if (!pendingWriteActions.length) {\n        callback(consumeResult())\n      } else {\n        // Make sure we do not call any write callback\n        pendingWriteActions.forEach((pendingWriteAction) => {\n          delete pendingWriteAction.writeCallback\n        })\n\n        // Wait for the last action to finish before calling the finish callback\n        pendingWriteActions[pendingWriteActions.length - 1].finishCallback = () => callback(consumeResult())\n      }\n    },\n\n    finishSync() {\n      sendResetIfNeeded()\n\n      const pendingData = pendingWriteActions\n        .map((pendingWriteAction) => {\n          // Make sure we do not call any write or finish callback\n          delete pendingWriteAction.writeCallback\n          delete pendingWriteAction.finishCallback\n          return pendingWriteAction.data\n        })\n        .join('')\n\n      return assign(consumeResult(), {\n        pendingData,\n      })\n    },\n\n    estimateEncodedBytesCount(data) {\n      // This is a rough estimation of the data size once it'll be encoded by deflate. We observed\n      // that if it's the first chunk of data pushed to the stream, the ratio is lower (3-4), but\n      // after that the ratio is greater (10+). We chose 8 here, which (on average) seems to produce\n      // requests of the expected size.\n      return data.length / 8\n    },\n\n    stop() {\n      removeMessageListener()\n    },\n  }\n}\n"],"mappings":"AAQA,SAASA,gBAAgB,EAAEC,iBAAiB,EAAEC,MAAM,EAAEC,aAAa,QAAQ,uBAAuB;AAElG,OAAM,SAAUC,oBAAoBA,CAClCC,aAA+B,EAC/BC,MAAqB,EACrBC,QAAgC;EAEhC,IAAIC,aAAa,GAAG,CAAC;EACrB,IAAIC,cAAc,GAAiB,EAAE;EACrC,IAAIC,qBAAiC;EAErC,IAAIC,iBAAiB,GAAG,CAAC;EACzB,IAAMC,mBAAmB,GAKpB,EAAE;EAEC,IAAMC,qBAAqB,GAAKb,gBAAgB,CACtDK,aAAa,EACbC,MAAM,EACN,SAAS,EACT,UAACQ,EAA6D;QAArDC,cAAc,GAAAD,EAAA,CAAAE,IAAA;IACrB,IAAID,cAAc,CAACE,IAAI,KAAK,OAAO,IAAKF,cAAc,CAACR,QAAmC,KAAKA,QAAQ,EAAE;MACvG;IACF;IAEAC,aAAa,IAAIO,cAAc,CAACG,oBAAoB;IACpDT,cAAc,CAACU,IAAI,CAACJ,cAAc,CAACK,MAAM,CAAC;IAC1CV,qBAAqB,GAAGK,cAAc,CAACM,OAAO;IAE9C,IAAMC,iBAAiB,GAAGV,mBAAmB,CAACW,KAAK,EAAE;IACrD,IAAID,iBAAiB,IAAIA,iBAAiB,CAACE,EAAE,KAAKT,cAAc,CAACS,EAAE,EAAE;MACnE,IAAIF,iBAAiB,CAACG,aAAa,EAAE;QACnCH,iBAAiB,CAACG,aAAa,CAACV,cAAc,CAACK,MAAM,CAACM,UAAU,CAAC;MACnE,CAAC,MAAM,IAAIJ,iBAAiB,CAACK,cAAc,EAAE;QAC3CL,iBAAiB,CAACK,cAAc,EAAE;MACpC;IACF,CAAC,MAAM;MACLd,qBAAqB,EAAE;MACvBZ,iBAAiB,CAAC,yCAAyC,CAAC;IAC9D;EACF,CAAC,CACF,CAAA2B,IAzBkC;EA2BnC,SAASC,aAAaA,CAAA;IACpB,IAAMC,MAAM,GACVrB,cAAc,CAACsB,MAAM,KAAK,CAAC,GAAG,IAAIC,UAAU,CAAC,CAAC,CAAC,GAAG7B,aAAa,CAACM,cAAc,CAACwB,MAAM,CAACvB,qBAAqB,CAAC,CAAC;IAC/G,IAAMU,MAAM,GAA8B;MACxCZ,aAAa,EAAAA,aAAA;MACbsB,MAAM,EAAAA,MAAA;MACNI,gBAAgB,EAAEJ,MAAM,CAACJ,UAAU;MACnCS,QAAQ,EAAE;KACX;IACD3B,aAAa,GAAG,CAAC;IACjBC,cAAc,GAAG,EAAE;IACnB,OAAOW,MAAM;EACf;EAEA,SAASgB,iBAAiBA,CAAA;IACxB,IAAIzB,iBAAiB,GAAG,CAAC,EAAE;MACzBL,MAAM,CAAC+B,WAAW,CAAC;QACjBC,MAAM,EAAE,OAAO;QACf/B,QAAQ,EAAAA;OACT,CAAC;MACFI,iBAAiB,GAAG,CAAC;IACvB;EACF;EAEA,OAAO;IACL4B,OAAO,EAAE,IAAI;IAEb,IAAIC,OAAOA,CAAA;MACT,OAAO7B,iBAAiB,KAAK,CAAC;IAChC,CAAC;IAED8B,KAAK,WAAAA,CAACzB,IAAI,EAAE0B,QAAQ;MAClBpC,MAAM,CAAC+B,WAAW,CAAC;QACjBC,MAAM,EAAE,OAAO;QACfd,EAAE,EAAEb,iBAAiB;QACrBK,IAAI,EAAAA,IAAA;QACJT,QAAQ,EAAAA;OACT,CAAC;MACFK,mBAAmB,CAACO,IAAI,CAAC;QACvBK,EAAE,EAAEb,iBAAiB;QACrBc,aAAa,EAAEiB,QAAQ;QACvB1B,IAAI,EAAAA;OACL,CAAC;MACFL,iBAAiB,IAAI,CAAC;IACxB,CAAC;IAEDgC,MAAM,WAAAA,CAACD,QAAQ;MACbN,iBAAiB,EAAE;MAEnB,IAAI,CAACxB,mBAAmB,CAACmB,MAAM,EAAE;QAC/BW,QAAQ,CAACb,aAAa,EAAE,CAAC;MAC3B,CAAC,MAAM;QACL;QACAjB,mBAAmB,CAACgC,OAAO,CAAC,UAACC,kBAAkB;UAC7C,OAAOA,kBAAkB,CAACpB,aAAa;QACzC,CAAC,CAAC;QAEF;QACAb,mBAAmB,CAACA,mBAAmB,CAACmB,MAAM,GAAG,CAAC,CAAC,CAACJ,cAAc,GAAG;UAAM,OAAAe,QAAQ,CAACb,aAAa,EAAE,CAAC;QAAzB,CAAyB;MACtG;IACF,CAAC;IAEDiB,UAAU,WAAAA,CAAA;MACRV,iBAAiB,EAAE;MAEnB,IAAMW,WAAW,GAAGnC,mBAAmB,CACpCoC,GAAG,CAAC,UAACH,kBAAkB;QACtB;QACA,OAAOA,kBAAkB,CAACpB,aAAa;QACvC,OAAOoB,kBAAkB,CAAClB,cAAc;QACxC,OAAOkB,kBAAkB,CAAC7B,IAAI;MAChC,CAAC,CAAC,CACDiC,IAAI,CAAC,EAAE,CAAC;MAEX,OAAO/C,MAAM,CAAC2B,aAAa,EAAE,EAAE;QAC7BkB,WAAW,EAAAA;OACZ,CAAC;IACJ,CAAC;IAEDG,yBAAyB,WAAAA,CAAClC,IAAI;MAC5B;MACA;MACA;MACA;MACA,OAAOA,IAAI,CAACe,MAAM,GAAG,CAAC;IACxB,CAAC;IAEDH,IAAI,WAAAA,CAAA;MACFf,qBAAqB,EAAE;IACzB;GACD;AACH","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}